a: During the 1950s and 1960s, the connectionist and the symbolic schools of artificial intelligence competed for researcher allegiance and funding, with the symbolic school winning by 1970.
[b]: During the 1950s and 1960s, the connectionist and symbolic schools of artificial intelligence competed for researcher allegiance and funding, with the symbolic school winning by 1970.

a: This "first neural network winter" lasted until the rise of connectionist school in the 1980s.
[b]: This "first neural network winter" lasted until the rise of the connectionist school in the 1980s.

[a]: It is often stated that neural networks were killed off by the 1969 publication of *Perceptrons* by Marvin Minsky and Seymour Papert.
b: It is often stated that the 1969 publication of *Perceptrons* by Marvin Minsky and Seymour Papert killed off neural networks.

[a]: This story is wrong on multiple accounts:
b: This story is wrong for multiple reasons:

[a]: Minsky and Papert had been working towards killing off neural networks since around 1965 by speaking at conferences and circulating preprints.
b: Minsky and Papert had been working toward killing off neural networks since around 1965 by speaking at conferences and circulating preprints.

[a]: It does not study multilayer perceptrons.
b: It does not study multilayered perceptrons.

[a]: By 1969, most researchers had already left connectionism, frustrated by the lack of progress, as they did not develop backpropagation or deep learning.
b: By 1969, frustrated by the lack of progress and because they had not developed backpropagation or deep learning, most researchers had already left connectionism.

[a]: In an 1993 interview, [Robert Hecht-Nielsen](https://en.wikipedia.org/wiki/Robert_Hecht-Nielsen) recounted an encounter between [Marvin Minsky](https://en.wikipedia.org/wiki/Marvin_Minsky) and the neural network community in the late 1980s[^1]:
b: In a 1993 interview, [Robert Hecht-Nielsen](https://en.wikipedia.org/wiki/Robert_Hecht-Nielsen) recounted an encounter between [Marvin Minsky](https://en.wikipedia.org/wiki/Marvin_Minsky) and the neural network community in the late 1980s[^1]:

a: However, it appears he had changed his mind later.
[b]: However, it appears that he had changed his mind later.

[a]: During his undergrad years, Minsky was deeply impressed by [Andrew Gleason](https://en.wikipedia.org/wiki/Andrew_M._Gleason),[^1] and decided to work on pure mathematics, resulting in his 1951 undergraduate thesis *A Generalization of Kakutani's Fixed-Point Theorem*, which extended an obscure fixed point theorem of [Kakutani](https://en.wikipedia.org/wiki/Shizuo_Kakutani) -- not [the famous version](https://en.wikipedia.org/wiki/Kakutani_fixed-point_theorem), as Kakutani proved more than one fixed point theorems.
b: During his undergraduate years, Minsky was deeply impressed by [Andrew Gleason](https://en.wikipedia.org/wiki/Andrew_M._Gleason),[^1] and decided to work on pure mathematics, resulting in his 1951 undergraduate thesis *A Generalization of Kakutani's Fixed-Point Theorem*, which extended an obscure fixed-point theorem of [Kakutani](https://en.wikipedia.org/wiki/Shizuo_Kakutani) -- not [the famous version](https://en.wikipedia.org/wiki/Kakutani_fixed-point_theorem) since Kakutani proved more than one fixed-point theorem.

a: If $f$ is a $\R^2$-valued continuous function on the unit sphere in $\R^3$, then for any side length $r \in (0, \sqrt 3)$, there exists $x_1, x_2, x_n$ on the sphere forming an equilateral triangle with side length $r$, such that $f(x_1) = f(x_2) = f(x_3)$.
[b]: If $f$ is an $\R^2$-valued continuous function on the unit sphere in $\R^3$, then for any side length $r \in (0, \sqrt{3})$, there exist $x_1, x_2, x_3$ on the sphere forming an equilateral triangle with side length $r$, such that $f(x_1) = f(x_2) = f(x_3)$.

a: The manuscript has "disappeared" [@minskySelectedPublicationsMarvin].
[b]: The manuscript "disappeared" [@minskySelectedPublicationsMarvin].

[a]: He then got interested in neural networks and reinforcement learning, and constructed a very simple electromechanical machine called SNARC.[^1]
b: He then became interested in neural networks and reinforcement learning and constructed a very simple electromechanical machine called SNARC.[^1]

a: The SNARC machine is a recurrent neural network, performing reinforcement learning by Hebbian learning rule.
[b]: The SNARC machine is a recurrent neural network that performs reinforcement learning by the Hebbian learning rule.

a: It simulates a mouse running around a maze, and the operator watches an indicator light showing the mouse.
[b]: It simulates a mouse running around a maze, while the operator watches an indicator light showing the mouse.

a: The operator can press a button as a reward signal, and this would cause an electric motor to turn a chain.
[b]: The operator can press a button as a reward signal, which would cause an electric motor to turn a chain.

a: The chain is clutched to rheostats that connect the neurons, and the stretch of the clutch is proportional to the charge in a capacitor.
[b]: The chain is clutched to rheostats that connect the neurons, with the stretch of the clutch being proportional to the charge in a capacitor.

[a]: During the operation of the neural network, the capacitor charges up if there is neural co-activation on the connection, and decays naturally, thus serving as a short-term memory.
b: During the operation of the neural network, the capacitor charges up if there is neural co-activation on the connection and decays naturally, thus serving as a short-term memory.

a: When the reward button is pressed, the clutches turn by an amount proportional to the co-activation of neural connections, thus completing the Hebbian learning.
[b]: When the reward button is pressed, the clutches turn by an amount proportional to the co-activation of neural connections, thereby completing the Hebbian learning.

a: This was the last we see Minsky's work with random neural networks.
[b]: This was the last we saw of Minsky's work with random neural networks.

[a]: He has crossed the Rubicon, away from the land of brute reason and into the land of genuine insight.
b: He had crossed the Rubicon, moving away from the land of brute reason and into the land of genuine insight.

[a]: Minsky would go on to write [@minskyComputationFiniteInfinite1967, Chapter 3], still the best introduction to McCulloch--Pitts neural networks.
b: Minsky would go on to write Chapter 3 of [@minskyComputationFiniteInfinite1967], which remains the best introduction to McCulloch--Pitts neural networks.

[a]: Reading the story, I was reminded of ["Sussman attains enlightenment"](https://web.archive.org/web/20231223082954/http://www.catb.org/jargon/html/koans.html), a [hacker koan](https://simple.wikipedia.org/wiki/Hacker_koan) about Minsky and his student [Sussman](https://en.wikipedia.org/wiki/Gerald_Jay_Sussman) [^1]:
b: Reading the story reminded me of "Sussman attains enlightenment" (https://web.archive.org/web/20231223082954/http://www.catb.org/jargon/html/koans.html), a hacker koan (https://simple.wikipedia.org/wiki/Hacker_koan) about Minsky and his student Sussman (https://en.wikipedia.org/wiki/Gerald_Jay_Sussman) [^1]:

[a]: A brief read of his ["reading list"](https://web.archive.org/web/20231007210930/http://aurellem.org/thoughts/html/sussman-reading-list.html)" shows where his loyalties lie: firmly in [the school of neats](https://en.wikipedia.org/wiki/Neats_and_scruffies).
b: A brief read of his "reading list" (https://web.archive.org/web/20231007210930/http://aurellem.org/thoughts/html/sussman-reading-list.html) shows where his loyalties lie: firmly in the school of neats (https://en.wikipedia.org/wiki/Neats_and_scruffies).

[a]: The SoM thesis states that "any brain, machine, or other thing that has a mind must be composed of smaller things that cannot think at all".
b: The SoM thesis states, "Any brain, machine, or other thing that has a mind must be composed of smaller things that cannot think at all".

a: Minsky described concretely how he expects a Society of Mind should work, based on his attempts at making Builder, a robot that can play with blocks:
[b]: Minsky concretely described how he expected a Society of Mind to work, based on his attempts at making Builder, a robot that can play with blocks:

a: In his 1988 book, Minsky described dozens of these heterogeneous components that he thought might make up a Society of Mind.
[b]: In his 1988 book, Minsky described dozens of these heterogeneous components he thought might make up a Society of Mind.

[a]: However, the precise details are not relevant,[^1] as he freely admits that those are conjectured details.
b: However, the precise details are not relevant[^1] as he freely admits they are conjectured.

[a]: Although Minsky meant for this SoM project to last a very long time, building up to general intelligence brick by brick, my literature search shows that there had been no new development since the 2000s, so the overview [@singhExaminingSocietyMind2003] still represents the SOTA of SoM.
b: Although Minsky meant for this SoM project to last a very long time, building up general intelligence brick by brick, my literature search indicates there has been no new development since the 2000s, so the overview [@singhExaminingSocietyMind2003] still represents the state of the art of SoM.

[a]: Perhaps a modern reincarnation of such an idea would be the dream of Internet agents operating in a digital economy, populated by agents performing simple tasks like spam filtering, listening for the price of petroleum.
b: Perhaps a modern reincarnation of such an idea would envisage Internet agents operating in a digital economy, populated by agents performing simple tasks such as spam filtering and monitoring the price of petroleum.

a: Some agents would interface with reality, while others interface with agents.
[b]: Some agents would interface with reality, while others would interface with agents.

a: Some agents are organized on a higher level into DAOs, made by a small committee of simple "manager agents" as the interface and coordinator of other agents.
[b]: Some agents are organized at a higher level into DAOs, created by a small committee of simple "manager agents" serving as the interface and coordinators for other agents.

a: DAOs can interface with other DAOs by little speaker-agents, who are themselves composed of a simple text filter for the torrent of information, which they then outsource to text-weaving agents to compose the actual messages that they would send out.
[b]: DAOs can interface with other DAOs through little speaker-agents, which consist of a simple text filter for the torrent of information and then outsource to text-weaving agents to compose the actual messages they send out.

a: In 1958, after a doctorate in mathematics, he met [Jean Piaget](https://en.wikipedia.org/wiki/Jean_Piaget) and became his pupil for four years.
[b]: In 1958, after earning a doctorate in mathematics, he met [Jean Piaget](https://en.wikipedia.org/wiki/Jean_Piaget) and became his pupil for four years.

a: This had a formative effect on Papert.
[b]: This experience had a formative effect on Papert.

[a]: Piaget's work was an important influence on the [constructivism philosophy in education](https://en.wikipedia.org/wiki/Constructivism_(philosophy_of_education)), and Papert would go on to make serious progress towards applying constructivism to real education.
b: Piaget's work significantly influenced the [constructivism philosophy in education](https://en.wikipedia.org/wiki/Constructivism_(philosophy_of_education)), and Papert would go on to apply constructivism to actual educational practices.

[a]: He was particularly hopeful that computers can realize the constructivist dream of unlocking the kaleidoscopic creativity that a child can construct.
b: He was particularly hopeful that computers could realize the constructivist dream by unlocking the kaleidoscopic creativity that a child possesses.

[a]: The main theme of Jean Piaget's work was developmental psychology, how children's understanding of the world changes as they grow up.
b: The main theme of Jean Piaget's work, developmental psychology, explored how children's understanding of the world changes as they grow.

[a]: What goes on in their mind as they progressively understand that things fall down, what dogs are, and solid steel sinks but hollow steel might float?
b: What goes on in their minds as they progressively understand that things fall, identify what dogs are, and discern that solid steel sinks but hollow steel might float?

[a]: Piaget discovered that children did not simply start with a blank sheet of paper and gradually fill in sketchy details of the true model, instead they constructed naive models of small aspects the world that, as it encounters phenomena it cannot explain, would be modified or completely replaced.
b: Piaget discovered that instead of starting with a blank sheet of paper and gradually filling in sketchy details of the true model, children constructed naive models of the world's small aspects, which they modified or completely replaced upon encountering unexplainable phenomena.

[a]: In this way, Piaget claimed that children are "little scientists".
b: In this way, Piaget likened children to "little scientists".

[a]: A small example would illustrate the idea.
b: A small example can illustrate the idea.

[a]: For example, when children see that a leaf floats on water, but a stone sinks, they might add a rule "Soft things float, while hard things sink.".
b: For instance, when children see that a leaf floats on water but a stone sinks, they might add the rule "Soft things float, while hard things sink".

[a]: Then they see that a hard plastic boat floats too, so they might add a rule "Except hard and light things also float.".
b: Then, seeing that a hard plastic boat also floats, they might amend the rule to "Except hard and light things also float".

[a]: Then they see that a large boat also float, so they rewrite the entire model to "Flat-bottomed things float, while small-bottomed things sink.".
b: Then, upon observing that a large boat floats as well, they might entirely rewrite the model to "Flat-bottomed things float, while small-bottomed things sink".

[a]: And so on.
b: This process continues.

a: The conservative way is to study how children tend to construct their scientific theories, and discover a sequence of evidences to present to the little scientists so that they reach the scientific orthodoxy as fast as possible.
[b]: The conservative approach involves studying how children construct their scientific theories and identifying a sequence of evidence to present to these young scientists so they can quickly reach scientific orthodoxy.

a: For example, we might present children with videos of curling and air hockey, and then let them play with an air hockey table, then guide them through exercises, so that they arrive as quickly as possible at the Newton's laws of motion.
[b]: For example, we might show children videos of curling and air hockey, then let them play with an air hockey table, following this with guided exercises, so they race through [animism](https://en.wikipedia.org/wiki/Animism), [Aristotelian physics](https://en.wikipedia.org/wiki/Aristotelian_physics), [impetus theory](https://en.wikipedia.org/wiki/Theory_of_impetus), etc, and end up with Newton's laws of motion.

[a]: Why go for the orthodoxy, when the [Duhem--Quine thesis](https://en.wikipedia.org/wiki/Duhem%E2%80%93Quine_thesis) tells us that evidence is never enough to constrain us to only one orthodoxy?
b: Why adhere to orthodoxy when the [Duhem–Quine thesis](https://en.wikipedia.org/wiki/Duhem%E2%80%93Quine_thesis) suggests evidence is insufficient to limit us to a single orthodoxy?

a: And given that objectively no theory deserves the name of "orthodoxy", how come the scientific "orthodoxy" became dominant?
[b]: And given that objectively no theory deserves the high name of "orthodoxy", how did the scientific "orthodoxy" become dominant?

a: A critical analysis of the history shows that its dominance over aboriginal and woman ways of knowing is merely a historical accident due to an alliance with [the hegemonic reason of the center over the periphery](https://en.wikipedia.org/wiki/World-systems_theory).
[b]: A critical analysis of the history shows that its dominance over Aboriginal and woman ways of knowing is merely a historical accident due to an alliance with [the hegemonic reason of the center over the periphery](https://en.wikipedia.org/wiki/World-systems_theory).

a: In the computer world, every children could program and construct "microworlds" from their own theories.
[b]: In the computer world, every child could program and construct "microworlds" from their own theories.

a: Almost every one of these problems were specifically targeted by *Perceptrons*.
[b]: Almost every one of these problems was specifically targeted by "Perceptrons".

[a]: Their work is detailed in my essay [*The Backstory of Backpropagation*](https://yuxi-liu-wired.github.io/blog/posts/backstory-of-backpropagation/#bernard-widrow-and-marcian-hoff).
b: Their work is detailed in my essay "The Backstory of Backpropagation" (https://yuxi-liu-wired.github.io/blog/posts/backstory-of-backpropagation/#bernard-widrow-and-marcian-hoff).

a: SRI had a strong AI program, which contained luminaries like [Nils Nilsson](https://en.wikipedia.org/wiki/Nils_John_Nilsson), [Charles Rosen](https://en.wikipedia.org/wiki/Charles_Rosen_(scientist)), [Duda](https://en.wikipedia.org/wiki/Richard_O._Duda), and [Hart](https://en.wikipedia.org/wiki/Peter_E._Hart).
[b]: SRI had a strong AI program, with luminaries such as [Nils Nilsson](https://en.wikipedia.org/wiki/Nils_John_Nilsson), [Charles Rosen](https://en.wikipedia.org/wiki/Charles_Rosen_(scientist)), [Duda](https://en.wikipedia.org/wiki/Richard_O._Duda), and [Hart](https://en.wikipedia.org/wiki/Peter_E._Hart).

[a]: In 1973, Duda and Hart published the famous "Duda and Hart" book on pattern classification [@dudaPatternClassificationScene1973].
b: In 1973, Duda and Hart published the famous book on pattern classification, "Duda and Hart" [@dudaPatternClassificationScene1973].

a: The second half was on "scene analysis", [of the kind that Minsky and Papert promoted](https://yuxi-liu-wired.github.io/blog/posts/reading-perceptron-book/#chapter-13).
[b]: The second half was on scene analysis, a symbolic-AI method for computer vision. Indeed, [Minsky and Papert promoted it as superior to perceptron networks](https://yuxi-liu-wired.github.io/blog/posts/reading-perceptron-book/#chapter-13).

a: It had become almost completely statistical, with new chapters on neural networks, Boltzmann machines, decision trees, and so on, and almost everything about scene analysis was deleted.
[b]: It had become almost completely statistical. There were new chapters on neural networks, Boltzmann machines, decision trees, and so on. In contrast, scene analysis was completely removed.

a: It says something about the obsolescence of scene analysis even in 2001, when Duda and Hart deleted half of their most famous book just to avoid talking about it.
[b]: It says something about the obsolescence of scene analysis even in 2001, as Duda and Hart deleted half of their most famous book just to avoid talking about it.

a: The only mention of "scene analysis" is as a condemnation:
[b]: The only mention of "scene analysis" is in the form of a condemnation:

a: While the book was published only in 1969, at almost the end of the perceptron controversy, the influence of Minsky and Papert were felt years earlier, as they attended conferences and disseminated their ideas via talks and preprints, sometimes fighting on stage.
[b]: Although the book was published only in 1969, close to the end of the perceptron controversy, the influence of Minsky and Papert had been felt years earlier as they attended conferences and disseminated their ideas through talks and preprints, sometimes quarreling on stage.

a: When *Perceptrons* was finally published in 1969, the connectionist camp had already become mostly empty.
[b]: When *Perceptrons* was finally published in 1969, the connectionist camp was already deserted.

a: The 1972 reprinting of *Perceptrons* had a handwritten note "In memory of Frank Rosenblatt".
[b]: The 1972 reprinting of *Perceptrons* included a handwritten note, "In memory of Frank Rosenblatt".

a: From our lack of information on Tobermory, we can infer that it was a failure.
[b]: From the obscurity of Tobermory, we can infer that it was a failure.

a: [@olazaranHistoricalSociologyNeural1991] collected evidence that the publication of *Perceptrons* was not the cause, but a "marker event", for the closure of the perceptron controversy, and the dominance of the symbolic AI school.
[b]: [@olazaranHistoricalSociologyNeural1991] gathered evidence that the publication of *Perceptrons* was not the cause but a "marker event" for the end of the perceptron controversy and the ascendancy of the symbolic AI school.

[a]: The book was not the neural network killer, but its epitaph.
b: The book was not the assassin of neural networks but rather their epitaph.

a: After the rise of connectionism in the 1980s, Anderson and Rosenfeld conducted interviews with the leading connectionists over the years of 1990s, connected into [@rosenfeldTalkingNetsOral2000].
[b]: Following the resurgence of connectionism in the 1980s, Anderson and Rosenfeld conducted interviews with prominent connectionists throughout the 1990s, compiled in [@rosenfeldTalkingNetsOral2000].

a: The perceptron controversy comes up several times.
[b]: The perceptron controversy is mentioned several times.

[a]: Reading the interviews gives one a distinct feeling of [*Rashomon*](https://en.wikipedia.org/wiki/In_a_Grove).
b: Reading the interviews imparts a distinct sensation of [*Rashomon*](https://en.wikipedia.org/wiki/In_a_Grove).

a: The same events become recounted in multiple perspectives.
[b]: The same events are recounted from multiple perspectives.

a: Jack D. Cowan gave an "eyewitness account" of Minsky and Papert's work in fighting the controversy, before the book was published in 1969.
[b]: Jack D. Cowan gave an "eyewitness account" of Minsky and Papert's role in the controversy, before the publication of the book in 1969.

a: As for Robert Hecht-Nielsen, we already saw how he believed Minsky to be "Darth Vader" and perhaps "the Devil".
[b]: Regarding Robert Hecht-Nielsen, we have already seen his belief that Minsky was "Darth Vader" and possibly "the Devil".

a: Unsurprisingly, he was the most bitter, and placed the blame for the neural network winter squarely on *Perceptrons*.
[b]: Unsurprisingly, he was the most embittered, and placed the blame for the 1970s neural network winter squarely on the publication of *Perceptrons*.

a: Minsky described how he and Papert came to be motivated to write the book:
[b]: Minsky described how he and Papert felt impelled to write the book:

a: The book is one of those things that have passed into the stuff of legend: often quoted, rarely read.
[b]: The book has become a true classic: everybody wants to have read and nobody wants to read.

a: However, for its historical importance, I have actually read the book.
[b]: Taking the opposite approach, I *have* read the book, despite not wanting to read it.

a: The content of the book can be cleanly separated into two parts.
[b]: Its content can be neatly divided into a greater and a lesser half.

a: Most of the book is a mathematical monograph on what functions can be implemented by a single perceptron with fixed featurizers, and the rest is a commentary on the wider implications of the mathematical monograph.
[b]: The greater half is a mathematical monograph on which functions can be implemented by a single perceptron with fixed featurizers, and the lesser half is a commentary on the wider implications of the monograph.

a: The impact of the work is exactly reversed: most of the impact is done by the commentary derived from the results, and essentially no impact is done by the mathematical results themselves.
[b]: The impact of the work is precisely reversed: most of the impact comes from the commentary derived from the results, and effectively no impact comes from the mathematical results themselves.

a: Despite this lopsidedness, the mathematical work is solid, and the perceptron controversy turns critically on the flexible interpretation of the solid mathematical work.
[b]: Despite this imbalance, the mathematical work is substantial, and the perceptron controversy turns critically on the pliable interpretation sprouting from the solid structure.

a: Therefore, I have described the mathematical content in a separate essay, [*Reading Perceptrons*](https://yuxi-liu-wired.github.io/blog/posts/reading-perceptron-book/), which I refer to occasionally to gloss their interpretation.
[b]: Therefore, I have detailed the mathematical content in a separate essay, [*Reading Perceptrons*](https://yuxi-liu-wired.github.io/blog/posts/reading-perceptron-book/), to which I refer occasionally to gloss their interpretation.

a: In the prologue, they staked their central point as follows: Connectionism is a mistake caused by a new generation of researchers ignorant of history; while the theorems of the *Perceptrons* book apply to only a single perceptron, the *lessons* apply to all neural networks.
[b]: In the prologue, they staked their claim thus: Connectionism is a mistake engendered by a new generation of researchers ignorant of history; though the theorems of the *Perceptrons* book apply to only a single perceptron, the *lessons* extend to all neural networks.

a: They also requested all AI researchers to convert to the Society of Mind hypothesis, or else face the charge of being un-thoughtful or drawing lines where none exists.
[b]: They also urged all AI researchers to adopt the Society of Mind hypothesis, or else face the charge of being unreflective or of drawing lines where none exists.

a: There are no general algorithms and no general problems.
[b]: There are no general algorithms and there are no general problems.

[a]: Either the algorithm is so general that it is as useless as "just try every algorithm" akin to Ross Ashby's homeostat, or it is useful but not general.
b: Either the algorithm is so general that it becomes as futile as "just try every algorithm," similar to Ross Ashby's homeostat, or it is effective but not universal.

a: There are *no* general and effective solutions to credit assignment, and there are *no* general and effective solutions to inventing novel features.
[b]: There are *no* universal and effective solutions to credit assignment, and there are *no* universally effective solutions to inventing novel features.

[a]: They ask the reader to think back to the lesson of the parity predicate from Chapter 10: Even though it is learnable by a two-layered perceptron network, it would involve weights exponential in the input pixel count, and therefore take a very long time to learn.
b: They ask the reader to think back to the lesson of the parity predicate from Chapter 10: even though it is learnable by a two-layered perceptron network, it would involve weights exponential in the input pixel count, and therefore would take a very long time to learn.

a: That is, a large fully connected network is useless anyway, except if it already decomposes into many tiny networks arranged in a Society of Mind.
[b]: That is, a large fully connected network is useless anyway unless it already decomposes into many tiny networks arranged in a Society of Mind.

a: It does not even have a convergence theorem, so in that sense it's worse than perceptron learning algorithm.
[b]: It does not even have a convergence theorem, so in that sense, it's worse than the perceptron learning algorithm.

a: If neural networks happen to work well on a problem, it merely shows that the problem is a good fit for this particular architecture trained in this particular way at this particular scale, not anything more general than that.
[b]: If neural networks happen to work well on a problem, it merely shows that the problem is a good fit for this particular architecture, trained in this particular way, at this particular scale. It does not imply anything more general.

a: Though lacking a theory of their own on the operation of multilayer perceptrons, Minsky and Papert then proceeded to interpret the connectionist experiment data as showing that neural networks will fail to scale.
[b]: Though lacking a theory of their own on the operation of multilayer perceptrons, Minsky and Papert proceeded to interpret the connectionist experiment data as showing that neural networks would fail to scale.

a: Connectionists demonstrated that two-layered perceptrons, where both layers were trainable, bypassed the limits described in Perceptrons.
[b]: Connectionists demonstrated that two-layered perceptrons, in which both layers were trainable, bypassed the limits described in Perceptrons.

a: That is, for any $X \subset R$, we have $\psi(X)=\psi(g(X))$.
[b]: That is, for any $X \subset R$, we have $\psi(X) = \psi(g(X))$.

a: While the connectionist authors interpreted the result as encouraging large-scale experiments, Minsky and Papert interpreted it as showing that the experiments will not scale, because the coefficients appear to grow exponentially, in the same way they proved in [Chapter 7](https://yuxi-liu-wired.github.io/blog/posts/reading-perceptron-book/#exm-line-symmetry).
[b]: While the connectionist authors saw the result as a hopeful sign, Minsky and Papert interpreted it as showing that the experiments wouldn't scale, because the coefficients appeared to grow exponentially -- in just the way they proved in [Chapter 7](https://yuxi-liu-wired.github.io/blog/posts/reading-perceptron-book/#exm-line-symmetry).

a: While it appears Minsky was the main author for the new prologue and epilogue, Papert solo-authored [@papertOneAIMany1988], an essay giving the controversy a uniquely Papert-styled spin.
[b]: While it appears that Minsky was the main author for the new prologue and epilogue, Papert solo-authored [@papertOneAIMany1988], an essay that gave the controversy a uniquely Papert-styled spin.

a: He then discussed the compute-first interpretation, "[The Bitter Lesson](https://web.archive.org/web/20190314204621/http://www.incompleteideas.net/IncIdeas/BitterLesson.html)" for the 1980s, before rejecting it.
[b]: He then discussed the compute-first interpretation, a "[bitter lesson](https://web.archive.org/web/20190314204621/http://www.incompleteideas.net/IncIdeas/BitterLesson.html)" for the 1980s, before rejecting it.

a: For two, he and Minsky were firm in their convictions that any uniform architecture must scale very badly, and no amount of compute or algorithmic advance could be more than a sterile extension.
[b]: For another, he and Minsky were firm in their conviction that any uniform architecture must scale very badly and that no amount of computing or algorithmic advancement could be anything more than a sterile extension.

a: If a high school student could bypass the XOR problem in a few minutes, how could it have possibly been news to the researchers in 1969?
[b]: If a high school student could bypass the XOR problem in a few minutes, how could it possibly have been news to the researchers in 1969?

a: On the electric engineering side, perceptron networks were studied under another name of "linear threshold logic" by electric engineers since 1950s, who clearly would not have bothered if they could not even make an XOR gate out of it.
[b]: On the electrical engineering side, perceptron networks were studied under the name of "linear threshold logic" by electrical engineers since the 1950s, who clearly would not have bothered if they could not even make an XOR gate out of it.

a: In fact, in a standard reference from 1965, there are chapters on "Single-Threshold-Element Synthesis by Iteration" -- learning a single perceptron by the perceptron learning algorithm -- and "Network Synthesis" -- which does not mean machine learning, but rather hand-designing perceptron networks.[@dertouzosThresholdLogicSynthesis1965]
[b]: In fact, in a standard reference from 1965, there are chapters on "Single-Threshold-Element Synthesis by Iteration" -- learning a single perceptron by the perceptron learning algorithm -- and "Network Synthesis" -- which does not imply machine learning, but rather hand-designing perceptron networks.[@dertouzosThresholdLogicSynthesis1965]

a: That is, for any $X \subset R$, we have $\psi(X)=\psi(g(X))$.
[b]: That is, for any $X \subset R$, we have $\psi(X) = \psi(g(X))$.

a: I believe it is because the *Perceptrons* book contained a host of problems that their restricted form of perceptron machines could not do.
[b]: I believe this is because *Perceptrons* contained a host of problems that their restricted form of perceptron machines could not do.

a: Teachers, who just wanted to spend two minutes on the first neural network winter, and move on, grabbed this XOR problem and pretended it is supposed to be the actual cause of it.
[b]: Teachers who just wanted to spend two minutes on the first neural network winter and move on, grabbed this XOR problem and pretended that it was the actual cause of it.

a: Rumelhart read the *Perceptrons* book very carefully in 1970, and it inspired him to go into neural network research, entirely missing its intended message.
[b]: Rumelhart read the *Perceptrons* book very carefully in 1970; it inspired him to go into neural network research, entirely missing its intended message.

a: After he developed backpropagation around 1982, he immediately tried training an MLP on the XOR problem:
[b]: After he developed backpropagation around 1982, he immediately tried to train an MLP on the XOR problem.

a: Before 1962, Rosenblatt had studied both theoretically and experimentally "four-layer perceptron with adaptive preterminal network", meaning a perceptron network with three layers, the first layer being random and fixed, and the second and third layers being learned [@rosenblattPrinciplesNeurodynamicsPerceptrons1962, Chapter 16].
[b]: Before 1962, Rosenblatt had studied both theoretically and experimentally "four-layer perceptron with adaptive preterminal network", which means a perceptron network with three layers: the first layer random and fixed, and the second and third layers learned [@rosenblattPrinciplesNeurodynamicsPerceptrons1962, Chapter 16].

a: Meanwhile during the early 1960s, Widrow and Hoff trained a single perceptron with gradient descent, then proceeded to try every trick *except* gradient descent to train a two-layered perceptron network.
[b]: Meanwhile, during the early 1960s, Widrow and Hoff trained a single perceptron with gradient descent, then proceeded to try every trick *except* gradient descent to train a two-layered perceptron network.

a: Hoff went on to coinvent the microprocessor at Intel, while Widrow applied a single perceptron to adaptive filter design, revolutionizing electric engineering in the process.
[b]: Hoff went on to co-invent the microprocessor at Intel, while Widrow applied a single perceptron to adaptive filter design, revolutionizing electrical engineering in the process.

a: They can train the final layer either by the perceptron learning rule of Rosenblatt, or the Widrow--Hoff rule of gradient descent on the squared error, but that is the extent of learning they could get the neural networks to do.
[b]: They could train the final layer either by the perceptron learning rule of Rosenblatt or by the Widrow--Hoff rule of gradient descent on the squared error, but that was the extent of the learning they could get the neural networks to do.

a: Rosenblatt's solution was mainly just randomization, because he mistakenly believed that the retina was randomly wired to the visual cortex, and he believed in emulating nature.
[b]: Rosenblatt's solution was mainly just randomization because he mistakenly believed that the retina was randomly wired to the visual cortex, and he believed in emulating nature.

a: Rosenblatt was working with the standard knowledge of neuroscience in his time, as the first of the Hubel and Wiesel series of cat-vision paper only appeared in 1959.
[b]: Rosenblatt was working with the standard knowledge of neuroscience in his time. He could not have known that neural connections were anything but random -- the first of the Hubel and Wiesel papers was published only in 1959.

a: However, it seems Rosenblatt simply had a strong attachment to randomization, as [@rosenblattPrinciplesNeurodynamicsPerceptrons1962] cites [@hubelReceptiveFieldsSingle1959] a few times, yet he kept randomizing the first layer.
[b]: However, it seems that Rosenblatt simply had a strong attachment to randomization, as [@rosenblattPrinciplesNeurodynamicsPerceptrons1962] cites [@hubelReceptiveFieldsSingle1959] several times, yet he still randomized the first layer for most experiments in the book.

a: Rosenblatt had also experimented with Hebbian learning [@rosenblattPrinciplesNeurodynamicsPerceptrons1962, Section 16.1], but since he did not use those extensively, I infer that it did not work well.
[b]: Rosenblatt had also experimented with Hebbian learning [@rosenblattPrinciplesNeurodynamicsPerceptrons1962, Section 16.1], but since he did not use this method extensively, I infer that it did not work well.

a: Widrow's solution was the MADALINE I rule, a complicated hack and a deadend.
[b]: Widrow's solution was the MADALINE I rule -- a complicated hack and a dead end.

a: Without an effective method to train the first layer, those who worked on two-layered neural networks had only two choices, either randomize the first layer, or design it by hand.
[b]: Without an effective method to train the first layer, those who worked on two-layered neural networks had only two choices: either randomize the first layer or design it by hand.

a: It is intuitively clear that if the raw input is featurized, then unless the features are adapted to the problem, the second layer would not be able to solve the problem.
[b]: It is intuitively clear that, unless the raw input is featurized and the features are adapted to the problem, the second layer will not be able to solve the problem.

a: Furthermore, if the first layer is not wired right, then the second layer would not be able to solve it either.
[b]: Furthermore, if the first layer is not wired correctly, the second layer will not be able to solve it either.

a: Not with three layers, because two layers are sufficient, and you have enough problem with two layers already.
[b]: Not with three layers, because two layers are sufficient, and you already have enough problems with two layers.

a: Not to give up, you try one of the hacks like the MADALINE I learning rule, or the Hebbian learning rule, but they are extremely fiddly and unable to learn most of the time unless you tune them just right, and it seems to require a different turning for problems even slightly more complex than the XOR problem.
[b]: Not to give up, you try one of the hacks like the MADALINE I learning rule, or the Hebbian learning rule, but they are extremely fiddly and unable to learn most of the time unless you tune them just right, and it seems to require a different tuning for problems even slightly more complex than the XOR problem.

a: And so we stand at the impasse of 1960s.
[b]: And so we stood at the impasse of the 1960s.

a: This is the occasion for small controversies by the "embodiment cognition" or "externalism" school like James Gibson and Rodney Brooks, but nothing that has come to anything yet.
[b]: This is the occasion for small controversies from the "embodiment cognition" or "externalism" school, like those of James Gibson and Rodney Brooks, but none that has led to anything substantial yet.

a: Nobody respectable claim that the brain is not connectionist,
[b]: None disputes that the brain is connectionist,

a: and the operation of any hardware is symbolic if you throw in enough symbols to discretely represent the real numbers.
[b]: and the operation of any hardware is symbolic if you use enough symbols to approximate the real numbers.

a: Minsky's commitment to elegant mathematics and simple programming structures led him to insist on things that he could prove theorems for -- and denounce empirical methods, especially if large sums of money might be "misdirected" to large scale neural network machines.
[b]: Minsky's commitment to elegant mathematics and simple programming structures led him to insist on things for which he could prove theorems -- and to denounce empirical methods, especially if large sums of money might be "misdirected" to large-scale neural network machines.

a: Papert's commitment to epistemological pluralism led him to insist on computers that resemble his ideal society -- and denounce a uniform computational structure like neural networks as flattening, enframing, and reproducing the hegemonic ideology of universalism.
[b]: Papert, committed to epistemological pluralism, had no choice but to insist on computers that resembled his ideal society -- and to denounce any uniform computational structure as flattening, enframing, and reproducing the hegemonic ideology of universalism.

a: They were trying to kill the project of general large-scale perceptrons that Frank Rosenblatt and the new connectionists in the 1980s worked towards.
[b]: They were trying to kill the project of general large-scale perceptrons, which both Frank Rosenblatt and the new connectionists in the 1980s were working towards.

a: We have large and homogeneous neural networks operating, and there are hints that some of them do have small groups of neurons representing symbolic concepts, and some of the symbolic concepts are engaged in serial computation across the layers.
[b]: There are large homogeneous neural networks that work, and there are hints that some of them have small groups of neurons representing symbolic concepts, some of which are engaged in serial computation across the layers.

a: However, in order to find these hints of symbolic programs, we had to take through a large detour through the brute reason of uniform neural network architecture, uniform GPU architecture, and uniform training objectives.
[b]: However, to find these hints of symbolic programs, we had to take a large detour through the brute reason of uniform neural network architecture, uniform GPU architecture, and uniform training objectives.

a: Neural networks does scale, 100 billion and counting.
[b]: Neural networks do scale, to 100 billion and counting.

a: Among all the objections to neural networks in the *Perceptrons* book, almost all were either disproven (the anti-scaling hypothesis), or made irrelevant (the perceptron learning rule).
[b]: Among all the objections to neural networks in the *Perceptrons* book, almost all were either disproved (the anti-scaling hypothesis) or made irrelevant (the perceptron learning rule).

[a]: Recognizing connectivity is hard and requires a serial program, but that's fine, because it's hard for humans too.
b: Recognizing connectivity is hard and requires a serial program, but that's fine because it's hard for humans too.

a: Well, it looks inefficient, except that neural networks is still the best we have even 30 years later, so perhaps the XOR problem is just something neural networks have to work hard for.
[b]: Well, it looks inefficient, except that neural networks are still the best we have even 30 years later, so perhaps the XOR problem is just something neural networks have to work hard for.

a: That's fine -- worst case, we'll just let the neural network offload those logical operations to a symbolic program, much like how humans use calculators.
[b]: That's fine -- in the worst case, we'll just let the neural network offload those logical operations to a symbolic program, much like how humans use calculators.

a: In any case, if human brains are neural networks, and they can instantly recognize symmetries, then it shows that there is *some* remaining architectural trick we don't yet know.
[b]: In any case, if human brains are neural networks and they can instantly recognize symmetries, then it shows that there is *some* remaining architectural trick we don't yet know.

a: Minsky and Papert hoped to show that there will be thousands of different problems, each requiring a bespoke algorithm implemented by a bespoke neural network.
[b]: Minsky and Papert hoped to show that there would be thousands of different problems, each requiring a bespoke algorithm implemented by a bespoke neural network.

a: In our current age, it seems like the other two camps have fallen largely into oblivion.
[b]: In our current age, it seems the other two camps have fallen largely into oblivion.

a: This section gives a brief history and orienting perspective of their key ideas.
[b]: This section gives a brief history and an orienting perspective of their key ideas.

a: The origin of cybernetics was tangled with the fast control of machinery in WWII.
[b]: The origin of cybernetics was entangled with the control of machinery in WWII, when you were either the quick or the dead.

a: Norbert Wiener, the mastermind of cybernetics, worked on anti-aircraft gun (AA guns) controllers.
[b]: Norbert Wiener, the mastermind of cybernetics, worked on anti-aircraft gun (AA gun) controllers.

[a]: As planes flew faster and higher than ever before, AA guns needed to "[lead the target](https://en.wikipedia.org/wiki/Deflection_(ballistics))" to a greater and greater extent.
b: As planes flew faster and higher than ever before, AA guns needed to "[lead the target](https://en.wikipedia.org/wiki/Deflection_(ballistics))" to an increasingly greater extent.

a: This put severe strain on the operator of the AA guns.
[b]: This put a severe strain on the operator of the AA guns.

a: Wiener constructed electromechanical devices that performed linear prediction of future trajectory of an aircraft based on its past trajectory.
[b]: Wiener constructed electromechanical devices that performed linear prediction of the future trajectory of an aircraft based on its past trajectory.

a: As the aircraft is a human-machine system, Wiener modelled both together as a synthetic whole.
[b]: As the aircraft was a human-machine system, Wiener modelled both together as a synthetic whole.

a: After the war, Wiener continued to work on cybernetics, using the analogies he accumulated during the war.
[b]: After the war, Wiener continued to work on cybernetics, using the analogies he had accumulated during the war.

a: Cybernetics entered the realm of popular consciousness with Wiener's 1948 bestseller *Cybernetics*.
[b]: Cybernetics entered the realm of popular consciousness with Wiener's 1948 bestseller, *Cybernetics*.

a: In it, we find a curious description of artificial intelligence and self-reproduction, but from the analog signal processing point of view, detailed in [*Cybernetic artificial intelligence*](https://yuxi-liu-wired.github.io/blog/posts/cybernetic-artificial-intelligence/).
[b]: In it, we find a curious description of artificial intelligence and self-reproduction from the analog signal processing point of view, detailed in [*Cybernetic artificial intelligence*](https://yuxi-liu-wired.github.io/blog/posts/cybernetic-artificial-intelligence/).

a: The short version of it is that it was an analog-circuit quine:
[b]: The short version is that it was an analog-circuit quine:

[a]: The cybernetic approach to AI is a strange chapter in the history of AI, filled with machines too *sui generis* to have followups.
b: The cybernetic approach to AI is a strange chapter in the history of AI, filled with machines too *sui generis* to have follow-ups.

a: It seems to me that there is no issue with building our way to AI one nonlinear filter at a time, except technical issues, but the technical issues are insurmountable.
[b]: It seems to me that there is no issue with building our way to AI one nonlinear filter at a time, except for technical issues, but the technical issues are insurmountable.

a: One day I might write an essay that give justice to the cybernetic approach, but as this essay is not on cybernetics, we will only give a whirlwind tour of highlights from the cybernetic approach to AI.
[b]: One day I might write an essay that gives justice to the cybernetic approach, but as this essay is not about cybernetics, we will only give a whirlwind tour of highlights from the cybernetic approach to AI.

a: In 1948, [Ross Ashby](https://en.wikipedia.org/wiki/W._Ross_Ashby) built a "[homeostat machine](https://en.wikipedia.org/wiki/Homeostat)", which consisted of four interacting electromechanical controllers.
[b]: In 1948, [Ross Ashby](https://en.wikipedia.org/wiki/W._Ross_Ashby) built a "[homeostat machine](https://en.wikipedia.org/wiki/Homeostat)", consisting of four interacting electromechanical controllers.

a: The other thing that Ashby is famous for is the "law of requisite variety", which is equivalent to the theorem that to solve $f(x) = y$, generically, the $x$ must have at least as many dimensions as $y$.
[b]: The other thing for which Ashby is famous is the "law of requisite variety", which is equivalent to the theorem that to solve $f(x) = y$, generically, the $x$ must have at least as many dimensions as the $y$.

a: Stafford Beer started his professional life as a business consultant, and devised methods to increase steel plant production efficiency.
[b]: Stafford Beer began his professional life as a business consultant and devised methods for increasing the efficiency of steel plant production.

[a]: He also investigated a wide variety of strange machines, including using an entire pond ecosystem as a computer for black-box homeostatic control [@beerProgressNoteResearch1962]:
b: He also explored a wide variety of unusual machines, including the use of an entire pond ecosystem as a computer for black-box homeostatic control [@beerProgressNoteResearch1962]:

a: According to [@pickeringScienceUnknowableStafford2004], Stafford Beer perhaps meant this literally:
[b]: Stafford Beer might have meant this literally, according to [@pickeringScienceUnknowableStafford2004]:

a: In 1971, he was asked to be the principal architect of [Project Cybersyn](https://en.wikipedia.org/wiki/Project_Cybersyn), a nervous system for the Chilean socialist economy by "algedonic control" ("algedonic" means "pain-pleasure").
[b]: In 1971, he was invited to become the principal architect of [Project Cybersyn](https://en.wikipedia.org/wiki/Project_Cybersyn), which was a nervous system for the Chilean socialist economy, employing "algedonic control" ("algedonic" is Greek for "pain-pleasure").

a: The project came to an abrupt end with a military coup in 1973 that instated free market economy for Chile.
[b]: This project, like president Allende, was shot in the head by the [1973 coup](https://en.wikipedia.org/wiki/1973_Chilean_coup_d'%C3%A9tat) that established a free market economy in Chile.

[a]: After this, he lived as a hermit, though he still published a few books and did occasional business consulting.
b: Following this, he lived as a hermit, although he continued to publish a few books and engaged in occasional business consulting.

a: [Gordon Pask](https://en.wikipedia.org/wiki/Gordon_Pask) in the 1950s made electrochemical "sensory organs".
[b]: In the 1950s, [Gordon Pask](https://en.wikipedia.org/wiki/Gordon_Pask) constructed electrochemical "sensory organs".

a: He prepared an acidic solution of metal salts (such as $\text{FeSO}_4$) in a dish, then immersed electrodes into the solution.
[b]: He prepared a dish of acidic metal salt solution (such as $\text{FeSO}_4$) and then immersed electrodes into it.

[a]: He reported success at growing some simple sensory organs in the dish [@gordonNaturalHistoryNetworks1959; @carianiEvolveEarEpistemological1993]:
b: He reported successful growth of some elementary sensory organs in the dish [@gordonNaturalHistoryNetworks1959; @carianiEvolveEarEpistemological1993]:

[a]: The details of the electrochemical ear is lost, and this line of research had no followups.
b: The details of the electrochemical ear are lost, and this research avenue had no subsequent follow-ups.

[a]: A faint echo of Pask's electrochemical ear was heard in late 1990s, when [Adrian Thompson used evolutionary algorithm](https://web.archive.org/web/20231212170749/https://www.damninteresting.com/on-the-origin-of-circuits/) to evolve circuits on [field-programmable gate arrays](https://en.wikipedia.org/wiki/Field-programmable_gate_array) to perform binary distinction between input signals $1 \mathrm{~kHz}$ and $10 \mathrm{~kHz}$.
b: A faint echo of Pask's electrochemical ear resurfaced in the late 1990s when [Adrian Thompson used an evolutionary algorithm](https://web.archive.org/web/20231212170749/https://www.damninteresting.com/on-the-origin-of-circuits/) to evolve circuits on [field-programmable gate arrays](https://en.wikipedia.org/wiki/Field-programmable_gate_array) that could differentiate between input signals of $1 \mathrm{~kHz}$ and $10 \mathrm{~kHz}$.

[a]: Curiously, some circuits succeeded at the task despite using no master clock signal.
b: Interestingly, some circuits achieved success in the task even without using a master clock signal.

[a]: Despite its early successes such as SHRDLU, LISP, and ELIZA, despite the support of most of AI researchers during 1960--2000, and despite the support of reigning cognitivists in the adjacent field of psychology, it never achieved something as successful as neural networks.
b: Despite its initial triumphs with SHRDLU, LISP, and ELIZA, the backing from the majority of AI researchers during 1960–2000, and endorsement from the dominant cognitivists in the adjacent field of psychology, it never attained a level of success comparable to that of neural networks.

a: In 1984, [Douglas Lenat](https://en.wikipedia.org/wiki/Douglas_Lenat) started the Cyc project, an ambitious attempt to scale symbolic AI up to the real world.
[b]: In 1984, [Douglas Lenat](https://en.wikipedia.org/wiki/Douglas_Lenat) began the Cyc project, an ambitious attempt to scale symbolic AI up to the real world.

[a]: Even from the vantage point of 1985, it was clear to all that there was a lot of common sense it had to incorporate [^1], although few could have predicted that Lenat doggedly kept pushing the project for over 30 years.
b: Even from the vantage point of 1985, it was clear to everyone that there was a significant amount of common sense it needed to incorporate [^1], although few could have predicted that Lenat would doggedly continue the project for over 30 years.

a: In 2016, Lenat finally declared Cyc project "done", and set about commercializing it.
[b]: In 2016, Lenat finally declared the Cyc project "done" and set about commercializing it.

a: That was essentially the last we have heard from Cyc.
[b]: That was essentially the last we heard from Cyc.

a: They saw with clarity that there is no shortcut to intelligence, no "Maxwell's equations of thought".
[b]: They saw clearly that there's no shortcut to intelligence, no "Maxwell's equations of thought".

a: They called the this enemy many names, such as "radical behaviorism", "Skinnerism", "perceptrons", "radical connectionism" and now "deep learning".
[b]: They called this enemy by many names, such as "radical behaviorism", "Skinnerism", "perceptrons", "radical connectionism", and now "deep learning".

a: Chomsky argued, and subsequent linguists have found, that the syntax of all human languages are at type-2 level, or [context-free grammar](https://en.wikipedia.org/wiki/Context-free_grammar).
[b]: Chomsky argued, and subsequent linguists have found, that the syntax of all human languages is at the type-2 level, or a [context-free grammar](https://en.wikipedia.org/wiki/Context-free_grammar).

a: None is regular and almost none is context-dependent.
[b]: None are regular and almost none are context-dependent.

a: Regular languages are modelled by finite state machines and cannot model arbitrarily deep recursion, while context-free languages allow arbitrarily deep recursion such as [center embedding](https://en.wikipedia.org/wiki/Center_embedding).
[b]: Regular languages are modeled by finite state machines and cannot model arbitrarily deep recursion, whereas context-free languages allow for arbitrarily deep recursion such as [center embedding](https://en.wikipedia.org/wiki/Center_embedding).

a: This would come into play later.
[b]: This fact would come into play later.

a: You might have heard of the controversy over Pirahã.
[b]: You might have heard of the controversy surrounding Pirahã.

a: It is mainly fought over the problem of recursion: does the Pirahã language have recursion or not?
[b]: The main fight is over the issue of recursion: does the Pirahã language have recursion?

a: Drawing the battle lines, I predicted that Pinker would argue that it must have recursion... and it turns out wrong.
[b]: Tracing the battle lines, I predicted that Pinker would argue that it must have recursion... and I turned out to be wrong.

a: Pinker went against Chomsky in this case.
[b]: Pinker argued against Chomsky in this case.

a: A key principle used by Chomsky was the "poverty of stimulus" argument, which he used to argue that humans must have a universal grammar built in at birth, because there is too little after-birth stimulus for humans to learn languages.
[b]: A key principle Chomsky used was the "poverty of stimulus" argument, which he used to argue that humans must have a universal grammar built in at birth, because children cannot possibly learn to speak when they are just a few years old -- they cannot possibly have heard and seen enough.

a: For one, true recursion can never be learned empirically, because true recursion can only be conclusively proven by seeing the infinitely many sentences.
[b]: For one thing, true recursion can never be learned empirically, because true recursion can only be conclusively proven by observing an infinite number of sentences.

a: Consider a simple example of the [balanced brackets language](https://en.wikipedia.org/wiki/Dyck_language).
[b]: Consider the simple example of the [balanced brackets language](https://en.wikipedia.org/wiki/Dyck_language).

a: A language learner observes sample sentences from the language and try to infer the language.
[b]: A language learner observes sample sentences from the language and tries to infer the language.

a: So we ask them to construct another sentence, and they confidently wrote `((((()))))`, but we announce to them that they were tricked!
[b]: So we ask them to construct another sentence, and they confidently write `((((()))))`, but then we inform them that they have been tricked!

[a]: The language is the balanced brackets language -- except that the brackets only go 4 levels deep.
b: The language is the balanced brackets language -- except that the brackets only extend 4 levels deep.

[a]: In general, only by seeing all levels of recursion can the balanced brackets language be *conclusively* learned.
b: In general, only by observing all levels of recursion can the balanced brackets language be *conclusively* learned.

[a]: Applied to linguistics, Chomsky claimed that statistical learning cannot learn syntax, and all attempts have been "colossal failures".
b: When applied to linguistics, Chomsky claimed that statistical learning cannot grasp syntax, and all attempts have been "colossal failures".

a: Well, finally a testable hypothesis!
[b]: At last, a testable hypothesis!

a: I asked GPT-4 to `Draw a syntax tree for "Can eagles that fly swim?"`, and got this:
[b]: I asked GPT-4 to `Draw a syntax tree for "Can eagles that fly swim?"`, and received this:

[a]: The code it gave failed on the first try, due to an environment variable issue of the Linux virtual machine it ran on.
b: The code it provided failed on the first attempt, owing to an environment variable issue on the Linux virtual machine where it was running.

[a]: We fixed it after two more plies of conversation.
b: We fixed it after two additional rounds of conversation.

a: As expected, Chomsky rejected statistical language learning right until the end.
[b]: As expected, Chomsky rejected statistical language learning to the very end.

[a]: [Peter Norvig](https://en.wikipedia.org/wiki/Peter_Norvig) gave a detailed analysis and a rebuttal in [@norvigChomskyTwoCultures2017].
b: [Peter Norvig](https://en.wikipedia.org/wiki/Peter_Norvig) provided a detailed analysis and a rebuttal in [@norvigChomskyTwoCultures2017].

a: [Gold's theorem about language learning in the limit](https://en.wikipedia.org/wiki/Language_identification_in_the_limit#Gold's_theorem) is occasionally quoted in the same context as a justification for the "poverty of stimulus argument".
[b]: [Gold's theorem about language learning in the limit](https://en.wikipedia.org/wiki/Language_identification_in_the_limit#Gold's_theorem) is occasionally cited in the same context as a justification for the "poverty of stimulus" argument.

a: It seems Chomsky did not consider it a relevant argument [@johnsonGoldTheoremCognitive2004], and I agree with Chomsky on that account, as Gold's theorem is extremely generic.
[b]: It appears Chomsky did not regard it as a relevant argument [@johnsonGoldTheoremCognitive2004], and I agree with Chomsky in this respect, as Gold's theorem is extremely generic.

a: During the second rise of neural networks, there was a bitter controversy that raged during the 1990s, but is essentially forgotten nowadays: the past tense debate.
[b]: After the second rise of neural networks, there was a bitter controversy that raged in the 1990s but is now essentially forgotten: the past tense debate.

a: On one side were the connectionists, and on the other side were the cognitivists like Steven Pinker and Gary Marcus [@pinkerFutureTense2002].
[b]: On one side were the connectionists, and on the other were the cognitivists, including Steven Pinker and Gary Marcus [@pinkerFutureTense2002].

a: Tellingly, both Steven Pinker and Gary Marcus were on the side of cognitivists.
[b]: Tellingly, both Steven Pinker and Gary Marcus sided with the cognitivists.

a: Steven Pinker is most famous for his other books like *The Blank Slate*, which applies Chomsky's linguistics to general psychology.
[b]: Steven Pinker is best known for his other books such as *The Blank Slate*, which applies Chomskyan linguistics to general psychology.

a: Human language has the distinctive fractal-like structure: for every rule, there are exceptions, and for every exception, there are exceptional exceptions, and so on.
[b]: Human language exhibits a distinctly fractal-like structure: for every rule, there are exceptions, and for every exception, there are exceptional exceptions, and so on.

[a]: Sejnowski in an interview described how quasi-regularity shows up in phonology, and offered a perfect demonstration project for the power of neural networks against the Chomskyans:
b: In an interview, Sejnowski described how quasi-regularity manifests in phonology and proposed an ideal demonstration project to showcase the power of neural networks against the Chomskyans:

[a]: [@sejnowskiDeepLearningRevolution2018, pages 75--78] recounts an anecdote about [Jerry Fodor](https://en.wikipedia.org/wiki/Jerry_Fodor), another prominent cognitivist.
b: [@sejnowskiDeepLearningRevolution2018, pp. 75--78] recounts an anecdote involving [Jerry Fodor](https://en.wikipedia.org/wiki/Jerry_Fodor), another prominent cognitivist.

a: While Fodor is no longer a hot name in AI nowadays, this anecdote illustrates the way of Chomsky.
[b]: Though Fodor is no longer a big name in AI nowadays, this anecdote illustrates the way of Chomsky.

a: Similarly, Gary Marcus has been consistently critical of neural network language models, at least since 1992 in [@marcusOverregularizationLanguageAcquisition1992].
[b]: Similarly, Gary Marcus has consistently criticized neural network language models since at least 1992 [@marcusOverregularizationLanguageAcquisition1992].

a: His theory of intelligence is essentially Chomskyan: neural networks can be intelligent, but only if they implement symbolic manipulation rules.
[b]: His theory of intelligence is fundamentally Chomskyan: neural networks can exhibit intelligence but only if they implement rules for symbolic manipulation.

a: Furthermore, a lot of symbolic rules must be built in at birth, as the poverty of stimulus precludes learning them empirically.
[b]: Moreover, many symbolic rules must be present at birth, by the poverty of stimulus.

a: This brief sketch suffices.
[b]: This sketch suffices.

[a]: And here is him saying in 2018, just in time to miss the Transformer revolution in natural language processing:
b: And here he is in 2018, just in time to overlook the Transformer revolution in natural language processing:

a: Not one to give up, he continued the same criticisms into the age of Transformer language models.
[b]: Not one to give up, he continued with the same criticisms into the age of Transformer language models.

a: If anything, I would grant that he is conveniently predictable[^1], and we would be unsurprised by his recent criticisms of deep learning [@marcusDeepLearningCritical2018] and [large language models](https://www.technologyreview.com/2020/08/22/1007539/gpt3-openai-language-generator-artificial-intelligence-ai-opinion/), [repeatedly](https://www.theatlantic.com/technology/archive/2023/03/ai-chatbots-large-language-model-misinformation/673376/).
b: If anything, I would concede that he is conveniently predictable[^1]; thus, we would not be surprised by his recent criticisms of deep learning [@marcusDeepLearningCritical2018] and [large language models](https://www.technologyreview.com/2020/08/22/1007539/gpt3-openai-language-generator-artificial-intelligence-ai-opinion/), [repeatedly](https://www.theatlantic.com/technology/archive/2023/03/ai-chatbots-large-language-model-misinformation/673376/).

[a]: [^1]: It would be funny if someone can train a language model to pass the "Gary Marcus test": pretend to be Gary Marcus in a Turing test setup.
b: [^1]: It would be amusing if someone could train a language model to pass the "Gary Marcus test": to pretend to be Gary Marcus in a Turing test setup.

a: If such a model passes, then either Marcus would admit that the language model makes sense, or that what he says is indistinguishable from nonsense.
[b]: If such a model were to pass, Marcus would either have to admit that the language model makes sense or accept that what he says is indistinguishable from nonsense.

